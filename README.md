# ScriptChain RAG Project

Welcome to **ScriptChain RAG**, a Retrieval-Augmented Generation (RAG) system designed to make exploring ScriptChain Health documentation easy and interactive. This project allows users to quickly find answers to questions by searching across product docs, blogs, and forums. It also highlights potential contradictions in the content for better clarity.

---

## Key Features

- **Document Ingestion**: Automatically reads and processes product documentation, blog posts, and forum threads.  
- **Smart Retrieval**: Uses a FAISS index to quickly find the most relevant chunks of information.  
- **Reranking for Accuracy**: Applies a machine learning model to reorder retrieved results for better answers.  
- **Contradiction Detection**: Identifies inconsistencies or conflicting information in the retrieved data.  
- **Interactive Q&A**: Users can ask their own questions in real-time through a simple command-line interface.  
- **FAISS Indexing**: Leverages vector search for semantic similarity, ensuring precise retrieval.

---

## Project Structure

Here’s how the project is organized:
Task-RAG/
│
├── docs/ # Source documents (product docs, blogs, forums)
├── examples/ # Example queries to test the system
├── indexes/ # FAISS index and metadata for retrieval
├── logs/ # Logs generated during processing
├── results/ # Output files and answers generated by the system
├── src/ # Core code: ingestion, retrieval, reranking, utils
├── venv/ # Python virtual environment
├── requirements.txt # List of required Python packages
└── README.md # This file
2. Set up a virtual environment
python -m venv venv
# Activate on Windows
venv\Scripts\activate
# Activate on macOS/Linux
source venv/bin/activate

3. Install dependencies
pip install -r requirements.txt

How to Use
Run Example Queries
python -m src.main


This will:

Ingest all documents (if not done already).

Run a set of example queries.

Launch an interactive Q&A mode for you to ask your own questions.

Interactive Q&A

Simply type your question and press Enter.

The system will return the most relevant answer from all ingested documents.

Type exit to quit the interactive mode.

How It Works

Ingest Documents: The system reads text from product docs, blogs, and forums.

Embedding & Indexing: Text is converted into embeddings using a SentenceTransformer model, then stored in a FAISS index for fast retrieval.

Retrieve Relevant Chunks: When you ask a question, the system searches for semantically similar chunks in the index.

Rerank Results: A cross-encoder reranker orders the retrieved results for higher accuracy.

Detect Contradictions: Optionally flags conflicting or inconsistent information.

Return Answer: Combines the top results into a coherent response.

Requirements

Python 3.9 or higher

Key Python packages:

faiss-cpu

sentence-transformers

transformers

numpy
